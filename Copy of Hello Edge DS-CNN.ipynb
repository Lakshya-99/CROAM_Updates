{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Hello Edge DS-CNN","provenance":[{"file_id":"1KhjMr3m7q8rhVBDNFW8L_xaexQd_74EF","timestamp":1590258806243}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8249gaqhyL22","colab_type":"text"},"source":["Research Paper - https://arxiv.org/pdf/1711.07128.pdf - https://github.com/ARM-software/ML-KWS-for-MCU <br>\n","Github Repo - https://github.com/rcmalli/keras-mobilenet"]},{"cell_type":"code","metadata":{"id":"D7bcBn78yI4t","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)\n","path = '/content/gdrive/My Drive/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1DdLaMuutSh","colab_type":"code","outputId":"a0d75932-87d5-47f4-e297-436bb073d20c","executionInfo":{"status":"ok","timestamp":1590342715173,"user_tz":-330,"elapsed":47148,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/gdrive/My Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7jhdG-JpxJCz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9db4340c-07d8-4949-8696-4c76062b94b2","executionInfo":{"status":"ok","timestamp":1590342732860,"user_tz":-330,"elapsed":5576,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}}},"source":["import librosa\n","import tensorflow as tf\n","import keras\n","from keras.layers import Dense,LSTM,GlobalMaxPool1D, Bidirectional \n","from keras.models import Sequential\n","import numpy as np\n","import os\n","from sklearn.utils import shuffle\n","from sklearn import metrics\n","import pickle\n","from scipy.io.wavfile import read,write\n","\n","from keras_applications.imagenet_utils import _obtain_input_shape\n","from keras import backend as K\n","from keras.layers import Input, Convolution2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation\n","from keras.models import Model\n","from keras.engine.topology import get_source_inputs\n","\n","'''\n","os.chdir is throwing some error which I am not able to resolve. For the time being, do the following to import this python script -\n","Find the file in the drive and download it, then reupload it in the /content folder of the colab file.\n","You will need to do this for every new runtime connection\n","'''\n","from depthwise_conv2d import DepthwiseConvolution2D"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"_scaFGj-yqqW","colab_type":"text"},"source":["#LOAD AND PROCESS INPUT"]},{"cell_type":"code","metadata":{"id":"W25qnUPKx1ar","colab_type":"code","colab":{}},"source":["# KEYWORD_FOLDER1= 'Bachao_Data_Old/'\n","# KEYWORD_FOLDER2= 'Bachao_Data_Babble_10dB'\n","# KEYWORD_FOLDER3 = 'Bachao_Data_Natural_10dB'\n","\n","KEYWORD_FOLDER4 = path + 'Help_Data_Old'\n","KEYWORD_FOLDER5 = path + 'Help_Data_10dB'\n","KEYWORD_FOLDER6= path + 'Help_Data_Natural_10dB'\n","\n","\n","NEGATIVE_FOLDER1 = 'Negative_Data/'\n","NEGATIVE_FOLDER2 = 'Negative_Data_10dB'\n","NEGATIVE_FOLDER3 = 'Negative_Data_Natural_10dB'\n","NEGATIVE_FOLDER4 = path + 'Negative_Data/'\n","NEGATIVE_FOLDER5 = path + 'Negative_Data_10dB'\n","NEGATIVE_FOLDER6 = path + 'Negative_Data_Natural_10dB'\n","\n","#OPPPOSITE_KEYWORD_FOLDER = 'Bachao_Data/'\n","KEYWORD_FOLDER_TEST = path + 'Bachao_Data_Test/'\n","NEGATIVE_FOLDER_TEST = path + 'Negative_Data_Test_Old/'\n","#OPPPOSITE_KEYWORD_FOLDER_TEST = 'Bachao_Data_Test/'\n","\n","INPUT_SHAPE = (376, 40)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7OkpCT2yaC4","colab_type":"code","colab":{}},"source":["def count_files(folder, extension):\n","\tcount = 0\n","\tfor file in os.listdir(folder):\n","\t\tif file.endswith(extension):\n","\t\t\tfile_path = os.path.join(folder, file)\n","\t\t\tcount += 1\n","\treturn count\n","\n","def load_data_folder(folder, is_keyword):\n","  num_samples = count_files(folder, '.wav')\n","  data_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","  data_Y = np.zeros((num_samples), dtype=np.float64)\n","\n","  count = 0\n","  for file in os.listdir(folder):\n","    if file.endswith('.wav'):\n","      file_path = os.path.join(folder, file)\n","      y, sr = librosa.load(file_path,sr=None)\n","      mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=128, n_fft=256, n_mfcc=20)\n","      mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n","      mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n","      data_X[count, :, :20] = mfcc.T\n","      data_X[count, :, 20:30] = mfcc_delta.T\n","      data_X[count, :, 30:] = mfcc_double_delta.T\n","      data_Y[count] = int(is_keyword)\n","      count += 1\n","      if count%50==0:\n","        print(count)\n","  return data_X, data_Y\n","\n","def load_data(folders):\n","\tnum_samples = sum([count_files(folder, '.wav') for folder, is_keyword in folders])\n","\tdata_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","\tdata_Y = np.zeros((num_samples), dtype=np.float64)\n","\tcount = 0\n","\tfor folder, is_keyword in folders:\n","\t\tnum_samples_folder = count_files(folder, '.wav')\n","\t\tdata_X[count:count+num_samples_folder, :, :], data_Y[count:count+num_samples_folder] = (\n","\t\t\tload_data_folder(folder, is_keyword))\n","\t\tcount += num_samples_folder\n","\treturn shuffle(data_X, data_Y, random_state=0)\n","\n","def load_train_data():\n","  #folders = [(NEGATIVE_FOLDER_TRAIN_1, False), (NEGATIVE_FOLDER_TRAIN_2, False), (NEGATIVE_FOLDER_TRAIN_3, False)]\n","  folders = [(KEYWORD_FOLDER4, True), (KEYWORD_FOLDER5, True), (NEGATIVE_FOLDER1, False), (NEGATIVE_FOLDER2, False), (NEGATIVE_FOLDER3, False), (NEGATIVE_FOLDER4, False)]\n","  #folders = [(KEYWORD_FOLDER4, True), (KEYWORD_FOLDER5, True), (KEYWORD_FOLDER6, True), (KEYWORD_FOLDER_TEST, True), (NEGATIVE_FOLDER1, False), (NEGATIVE_FOLDER2, False), (NEGATIVE_FOLDER3, False), (NEGATIVE_FOLDER4, False), (NEGATIVE_FOLDER5, False), (NEGATIVE_FOLDER6, False), (NEGATIVE_FOLDER_TEST, False)]\n","  return load_data(folders)\n","\n","def load_test_data():\n","  #folders = [(NEGATIVE_FOLDER_TEST, True)]\n","  folders = [(KEYWORD_FOLDER_TEST, True), (NEGATIVE_FOLDER_TEST, False), (KEYWORD_FOLDER6, True), (NEGATIVE_FOLDER5, False), (NEGATIVE_FOLDER6, False)] \n","  return load_data(folders)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VETxO_gH7Pdm","colab_type":"code","colab":{}},"source":["train_X1, train_Y1 = load_train_data()\n","print(\"Train data extracted\")\n","\n","test_X1, test_Y1 = load_test_data()\n","print(\"Test data extracted\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMOljQ3qRf0E","colab_type":"code","outputId":"030c1a96-ff73-4828-c2b1-337331cf30df","executionInfo":{"status":"ok","timestamp":1590266802590,"user_tz":-330,"elapsed":11275,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["with open(\"1help_data_total_hari_train_x.pickle\", \"wb\") as f:\n","  pickle.dump(train_X1, f)\n","print(\"Train set features done\")\n","with open(\"1help_data_total_hari_train_y.pickle\", \"wb\") as f:\n","  pickle.dump(train_Y1, f)\n","print(\"Train set labels done\")\n","\n","with open(\"1help_data_total_hari_test_x.pickle\", \"wb\") as f:\n","  pickle.dump(test_X1, f)\n","print(\"Test set features done\")\n","with open(\"1help_data_total_hari_test_y.pickle\", \"wb\") as f:\n","  pickle.dump(test_Y1, f)\n","print(\"Test set labels done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train set features done\n","Train set labels done\n","Test set features done\n","Test set labels done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UVW_Qvwew9ZE","colab_type":"code","outputId":"6a716004-4942-493f-d843-c0aee1eeeef2","executionInfo":{"status":"ok","timestamp":1590258445852,"user_tz":-330,"elapsed":1217,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["activ_dir = 'white_noise'\n","fs, x = read(path + 'white_noise.wav')\n","file_size = x.shape[0]\n","segment_time = 3.0\n","segment_samples = int(segment_time * fs)\n","no_of_segments = int(file_size/segment_samples)\n","\n","# for i in range(no_of_segments - 1):\n","#   file_name = '{}_{}.wav'.format(activ_dir, i)\n","#   x_temp = x[i*segment_samples:(i+1)*segment_samples]\n","#   write(path + 'white_noice/' + file_name, fs, x_temp)\n","\n","print(fs)\n","print(x.shape)\n","print(file_size)\n","print(segment_samples)\n","print(no_of_segments)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["16000\n","(24000000,)\n","24000000\n","48000\n","500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z-YgqF6Tyogf","colab_type":"code","outputId":"5b95c9ab-23e1-4b3b-a4c6-eb84b1380df6","executionInfo":{"status":"ok","timestamp":1590259571658,"user_tz":-330,"elapsed":1856,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["# with open(path + 'train_x_extra_noise.pickle', 'rb') as f:\n","#   train_X = pickle.load(f)\n","# with open(path + 'train_y0.pickle', 'rb') as f:\n","#   train_Y = pickle.load(f)\n","\n","# print(\"Train data extracted\")\n","\n","# print(train_Y.sum())\n","# print(train_X.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train data extracted\n","2518.0\n","(1526, 376, 40)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vj-lPRRS-YIN","colab_type":"code","outputId":"386f88f0-1756-46c1-ffa2-7b7476850fe1","executionInfo":{"status":"ok","timestamp":1590267176781,"user_tz":-330,"elapsed":2411,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["print(train_X1.shape)\n","print(train_Y1.shape)\n","print(test_X1.shape)\n","print(test_Y1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(6486, 376, 40)\n","(6486,)\n","(100, 376, 40)\n","(100,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"azdZw-sUzeK_","colab_type":"code","outputId":"31b8741f-705b-4116-a505-a74991017fc6","executionInfo":{"status":"ok","timestamp":1590266884541,"user_tz":-330,"elapsed":3464,"user":{"displayName":"Watch Project","photoUrl":"","userId":"15916048580519237781"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["np.random.seed(0)\n","np.random.shuffle(train_X1)\n","np.random.shuffle(train_Y1)\n","\n","train_X_shuffle = train_X1\n","train_Y_shuffle = train_Y1\n","\n","train_X_shuffle = train_X_shuffle[:,:,:,np.newaxis]\n","\n","print(train_X_shuffle.shape)\n","print(train_Y_shuffle.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(6486, 376, 40, 1)\n","(6486,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RzcNElPGzreC","colab_type":"code","colab":{}},"source":["import sklearn\n","train_X_cv, test_X_cv, train_Y_cv, test_Y_cv = sklearn.model_selection.train_test_split(train_X_shuffle, train_Y_shuffle, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YR6FuKaDywOW","colab_type":"text"},"source":["#MODEL"]},{"cell_type":"code","metadata":{"id":"e86H5MrHyxfB","colab_type":"code","colab":{}},"source":["def MobileNet(input_shape=(376,40,1), alpha=1, classes=1):\n","    \"\"\"Instantiates the MobileNet.Network has two hyper-parameters\n","        which are the width of network (controlled by alpha)\n","        and input size.\n","        \n","        # Arguments\n","            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","                to use as image input for the model.\n","            input_shape: optional shape tuple, only to be specified\n","                if `include_top` is False (otherwise the input shape\n","                has to be `(224, 224, 3)` (with `channels_last` data format)\n","                or `(3, 224, 244)` (with `channels_first` data format).\n","                It should have exactly 3 inputs channels,\n","                and width and height should be no smaller than 96.\n","                E.g. `(200, 200, 3)` would be one valid value.\n","            alpha: optional parameter of the network to change the \n","                width of model.\n","            shallow: optional parameter for making network smaller.\n","            classes: optional number of classes to classify images\n","                into.\n","        # Returns\n","            A Keras model instance.\n","        \"\"\"\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = Convolution2D(int(32 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(img_input)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = DepthwiseConvolution2D(int(32 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(int(32 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = DepthwiseConvolution2D(int(32 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(int(32 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    out = Dense(classes, activation='softmax')(x)\n","\n","    model = Model(img_input, out, name='mobilenet')\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLJ1gjbdtFFT","colab_type":"code","colab":{}},"source":["model = MobileNet()\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK2hgu3fENgP","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","model.compile(optimizer = Adam(learning_rate = 0.1),loss = tf.keras.losses.BinaryCrossentropy(),metrics = ['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7JMmm63g3NW","colab_type":"code","colab":{}},"source":["model.fit(x=train_X_shuffle,y=train_Y_shuffle,batch_size=64,epochs=100,validation_split=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1QHCEsGhhfG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}