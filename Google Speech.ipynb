{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Google Speech.ipynb","provenance":[{"file_id":"1CWVVOusrDDhO830q-fBXOQVj8Gg97CxV","timestamp":1591310227907}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"S2vBaav6HLif","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","import os\n","os.chdir('/content/drive/My Drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zotACbPSKtIz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":689},"executionInfo":{"status":"ok","timestamp":1594368505687,"user_tz":-330,"elapsed":1466,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"ec0cd2b5-94e0-4fb5-d787-da4a7ff721fa"},"source":["os.listdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Colab Notebooks',\n"," 'Help.zip',\n"," 'Negative_Data.zip',\n"," 'help_trimmed_train_x.pickle',\n"," 'help_trimmed_test_y.pickle',\n"," 'help_trimmed_train_y.pickle',\n"," 'help_trimmed_test_x.pickle',\n"," 'help_trimmed.h5',\n"," 'Help',\n"," 'Negative',\n"," 'new.wav',\n"," 'model1.json',\n"," 'model1.h5',\n"," 'model2.json',\n"," 'model2.h5',\n"," 'model3.json',\n"," 'model3.h5',\n"," 'Models',\n"," 'speech_commands_v0.02.tar.gz',\n"," 'Google_Speech',\n"," 'Google_Noise',\n"," 'model3_1.json',\n"," 'model3_1.h5',\n"," 'Google_Sample',\n"," 'google_trimmed_train_x.pickle',\n"," 'google_trimmed_train_y.pickle',\n"," 'google_mix_help_train_y.pickle',\n"," 'train_x_extra_noise.pickle',\n"," 'google_mix_help_train_x.pickle',\n"," 'model_a.json',\n"," 'model_a.h5',\n"," 'Hey Siri Models.gslides',\n"," 'Wake-word Detection Update.gslides',\n"," 'Object Detection.gslides',\n"," 'Images',\n"," 'coco.names',\n"," 'yolov3.weights',\n"," 'futur.ttf',\n"," 'Google_Sample2',\n"," 'Vocal_Noise']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"zJskeBdvfsf6","colab_type":"code","colab":{}},"source":["# !tar -xf speech_commands_v0.02.tar.gz -C ./Google_Speech"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kD7_Jdf9ZiB","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from scipy.io.wavfile import read\n","from scipy.io.wavfile import write\n","\n","import random\n","from random import randint\n","\n","import wave\n","\n","labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\", \"one\", \"two\", \"three\", \"four\",\n","\"five\", \"six\", \"seven\", \"eight\", \"nine\", \"bed\", \"bird\", \"cat\", \"dog\", \"happy\", \"house\", \"marvin\", \"sheila\", \"tree\", \"wow\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMpVyHHs5zL2","colab_type":"code","colab":{}},"source":["#Cutting a random section\n","def cut_random_section(noise2, size2):\n","    size21 = noise2.size\n","    starting_point2 = randint(0,(noise2.size - size2))\n","    end_point2 = starting_point2 + size2\n","    noise_cut_part2 = noise2[starting_point2:end_point2]\n","    return noise_cut_part2\n","\n","#Mixing\n","def mix(audio1, noise1, snr1):\n","    audio_max = max(audio1)\n","    if audio_max==0:\n","        audio_max = int(np.random.uniform(0.7,1)*32767)\n","    audio1 = audio1*1.\n","    audio1 = audio1/audio_max\n","    print(audio1,noise1)\n","    noise1 = cut_random_section(noise1, audio1.size)\n","    noise1 = noise1*1.\n","    print(noise1)\n","    print(audio1.size, noise1.size)\n","    noise1 = noise1/max(noise1)\n","    gain = pow(10,(snr1/10.))\n","    numerator = np.mean(abs(audio1)**2)\n","    denominator = numerator/gain\n","    noise_power = np.mean(abs(noise1)**2)\n","    mult_value = (denominator/noise_power)**0.5\n","    noisy1 = audio1 + noise1*mult_value\n","    if max(audio1)==0:\n","        noisy1 = noise1\n","    else:    \n","        noisy1 = noisy1/max(noisy1)\n","    noisy1 = np.array(noisy1*audio_max, dtype='int16')\n","    # print(audio_max)\n","    return noise1*mult_value, mult_value, noisy1\n","\n","def readwav(file):\n","    \"\"\"\n","    Read a wav file.\n","    Returns the frame rate, sample width (in bytes) and a numpy array\n","    containing the data.\n","    This function does not read compressed wav files.\n","    \"\"\"\n","    wav = wave.open(file)\n","    rate = wav.getframerate()\n","    nchannels = wav.getnchannels()\n","    sampwidth = wav.getsampwidth()\n","    nframes = wav.getnframes()\n","    data = wav.readframes(nframes)\n","    wav.close()\n","    array = _wav2array(nchannels, sampwidth, data)\n","    return rate, sampwidth, array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOhYEAJdhOSC","colab_type":"code","colab":{}},"source":["# !pip install soundfile\n","# import soundfile\n","\n","# def convertAllFilesInDirectoryTo16Bit(directory):\n","#     for file in os.listdir(directory):\n","#          if(file.endswith('.wav')):\n","#              nameSolo = file.rsplit('.', 1)[0]\n","#              print(directory + nameSolo )\n","#              data, samplerate = soundfile.read(directory + file)                \n","\n","#              soundfile.write(directory + file, data, samplerate, subtype='PCM_16')\n","#              print(\"converting \" + file + \"to 16 - bit\")\n","\n","# convertAllFilesInDirectoryTo16Bit('Vocal_Noise/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ye8G8QTHnHZs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"error","timestamp":1594368603322,"user_tz":-330,"elapsed":39430,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"79bd2ab8-4404-439b-cfce-c11042033482"},"source":["snr_dB = 10\n","\n","noise_files = os.listdir('Vocal_Noise')\n","for label in labels:\n","  try:  \n","    os.mkdir(\"./Google_Sample2/\" + str(label))\n","  except:\n","    0+0\n","  files = os.listdir(\"Google_Speech/\" + str(label))\n","\n","  # #Sample and store\n","  # if len(files) > 30:\n","  #   sampling = random.choices(files, k=30)\n","  # else:\n","  #   sampling = files\n","\n","  # for temp in sampling:\n","  #   fs,x = read('Google_Speech/' + label + '/' + temp)\n","  #   os.chdir(\"./Google_Sample/\" + str(label))\n","  #   write(temp[:-4] + '_' + label, fs, x)\n","  #   os.chdir(\"../../\")  \n","  # print(label, len(sampling))\n","\n","  #Sample, add noise and store\n","  for noise in noise_files:\n","    fs, noise_file = read('Vocal_Noise/' + noise)\n","\n","    if len(files) > 30:\n","      sampling = random.choices(files, k=30)\n","    else:\n","      sampling = files\n","\n","    for temp in sampling:\n","      fs,x = read('Google_Speech/' + label + '/' + temp)\n","      noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n","      os.chdir(\"./Google_Sample2/\" + str(label))\n","      write(temp[:-4] + '_' + label + '_' + noise[:-4], fs, noisy) \n","      os.chdir(\"../../\")   \n","    print(noise)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-7.93210121e-05 -4.75926073e-04 -3.17284049e-04 ... -7.13889109e-04\n"," -3.96605061e-04 -3.96605061e-04] [[   0   -1]\n"," [  -1    0]\n"," [  -1    0]\n"," ...\n"," [-568 -341]\n"," [-599 -314]\n"," [-491 -353]]\n","[]\n","16000 0\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9fe2a1991131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Google_Speech/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mnoise_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_dB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Google_Sample2/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-4ffe9558bbea>\u001b[0m in \u001b[0;36mmix\u001b[0;34m(audio1, noise1, snr1)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnoise1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnr1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"]}]},{"cell_type":"code","metadata":{"id":"H3yDfF5sOGQy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9qhdAPyOGXM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591597780998,"user_tz":-330,"elapsed":4587,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"d3389b81-bbc7-4f6a-c325-2f94c5c48aa9"},"source":["import librosa\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense,LSTM,GlobalMaxPool1D, Bidirectional \n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import TensorBoard\n","import numpy as np\n","import os\n","from sklearn.utils import shuffle\n","from sklearn import metrics\n","import pickle\n","from scipy.io.wavfile import read,write\n","import pickle\n","\n","from datetime import datetime\n","from packaging import version\n","\n","tf.keras.backend.set_floatx('float64')\n","\n","print(\"TensorFlow version: \", tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow version:  2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UaiDPVuiOKaF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1591597780999,"user_tz":-330,"elapsed":4052,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"99b6457c-3149-4113-8deb-6d0c28a4dab1"},"source":["INPUT_SHAPE = (126, 40)\n","dropout = 0.2\n","var = 0\n","folders = [(\"Google_Sample/\" + str(label), False) for label in labels]\n","print(folders)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('Google_Sample/yes', False), ('Google_Sample/no', False), ('Google_Sample/up', False), ('Google_Sample/down', False), ('Google_Sample/left', False), ('Google_Sample/right', False), ('Google_Sample/on', False), ('Google_Sample/off', False), ('Google_Sample/stop', False), ('Google_Sample/go', False), ('Google_Sample/zero', False), ('Google_Sample/one', False), ('Google_Sample/two', False), ('Google_Sample/three', False), ('Google_Sample/four', False), ('Google_Sample/five', False), ('Google_Sample/six', False), ('Google_Sample/seven', False), ('Google_Sample/eight', False), ('Google_Sample/nine', False), ('Google_Sample/bed', False), ('Google_Sample/bird', False), ('Google_Sample/cat', False), ('Google_Sample/dog', False), ('Google_Sample/happy', False), ('Google_Sample/house', False), ('Google_Sample/marvin', False), ('Google_Sample/sheila', False), ('Google_Sample/tree', False), ('Google_Sample/wow', False)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gdbea5CvOXUf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eu_g-jRvpI5CR9KbD7ZwuDCszZkmE1ZU"},"executionInfo":{"status":"ok","timestamp":1591604707426,"user_tz":-330,"elapsed":6316405,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"e8e85c1f-a595-404c-ad35-dd4ec5a62cc6"},"source":["def count_files(folder, extension):\n","\tcount = 0\n","\tfor file in os.listdir(folder):\n","\t\tif file.endswith(extension):\n","\t\t\tfile_path = os.path.join(folder, file)\n","\t\t\tcount += 1\n","\treturn count\n","\n","def load_data_folder(folder, is_keyword):\n","  num_samples = len(os.listdir(folder))\n","  data_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","  data_Y = np.zeros((num_samples), dtype=np.float64)\n","  count = 0\n","  for file in os.listdir(folder):\n","    # if file.endswith('.wav'):\n","      file_path = os.path.join(folder, file)\n","      y, sr = librosa.load(file_path,sr=None)\n","      temp = librosa.feature.mfcc(y=y, sr=sr, hop_length=128, n_fft=256, n_mfcc=20)\n","      if temp.shape != (20, 126):\n","        continue\n","      idx = (INPUT_SHAPE[0]-temp.shape[1])//2\n","      mfcc = np.zeros((20,126))\n","      if temp.shape[1]%2 == 0:\n","        mfcc[:, idx: INPUT_SHAPE[0] - idx] = temp\n","      else:\n","        mfcc[:, idx: INPUT_SHAPE[0] - idx - 1] = temp\n","      mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n","      mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n","      data_X[count, :, :20] = mfcc.T\n","      data_X[count, :, 20:30] = mfcc_delta.T\n","      data_X[count, :, 30:] = mfcc_double_delta.T\n","      data_Y[count] = int(is_keyword)\n","      count += 1\n","      if count%50==0:\n","        print(count)\n","  return data_X, data_Y\n","\n","def load_data(folders):\n","\tnum_samples = sum(len(os.listdir(folder)) for (folder,_) in folders)\n","\tdata_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","\tdata_Y = np.zeros((num_samples), dtype=np.float64)\n","\tcount = 0\n","\tfor folder, is_keyword in folders:\n","\t\tnum_samples_folder = len(os.listdir(folder))\n","\t\tdata_X[count:count+num_samples_folder, :, :], data_Y[count:count+num_samples_folder] = (load_data_folder(folder, is_keyword))\n","\t\tcount += num_samples_folder\n","\treturn shuffle(data_X, data_Y, random_state=0)\n","\n","train_X0, train_Y0 = load_data(folders)\n","print(\"Train data extracted\")\n","print(train_X0.shape, train_Y0.shape)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"GXKSrT0DO2lM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1591604767062,"user_tz":-330,"elapsed":13170,"user":{"displayName":"Watch Project","photoUrl":"","userId":"06359571817193298708"}},"outputId":"7563f046-aa81-4ec2-981d-d0b316d4c001"},"source":["import pickle\n","\n","with open(\"google_vocal_train_x.pickle\", \"wb\") as f:\n","  pickle.dump(train_X0, f)\n","print(\"Train set features done\")\n","with open(\"google_vocal_train_y.pickle\", \"wb\") as f:\n","  pickle.dump(train_Y0, f)\n","print(\"Train set labels done\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train set features done\n","Train set labels done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xXcmbgrkPM9F","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wo5LG0ZfxjAW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}