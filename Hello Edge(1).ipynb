{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hello Edge.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8249gaqhyL22","colab_type":"text"},"source":["Research Paper - https://arxiv.org/pdf/1711.07128.pdf - https://github.com/ARM-software/ML-KWS-for-MCU <br>\n","Github Repos - <br>\n","https://github.com/rcmalli/keras-mobilenet <br>\n","https://github.com/ZainNasrullah/music-artist-classification-crnn"]},{"cell_type":"code","metadata":{"id":"D7bcBn78yI4t","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)\n","path = '/content/gdrive/My Drive/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jhdG-JpxJCz","colab_type":"code","colab":{}},"source":["import librosa\n","import tensorflow as tf\n","import keras\n","from keras.layers import Dense,LSTM,GRU,GlobalMaxPool1D,Bidirectional,MaxPooling2D\n","from keras.models import Sequential\n","import numpy as np\n","import os\n","from sklearn.utils import shuffle\n","from sklearn import metrics\n","import pickle\n","from scipy.io.wavfile import read,write\n","\n","from keras_applications.imagenet_utils import _obtain_input_shape\n","from keras import backend as K\n","from keras.layers import Input, Convolution2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, Dropout, Permute, Reshape\n","from keras.models import Model\n","from keras.engine.topology import get_source_inputs\n","\n","'''\n","os.chdir is throwing some error which I am not able to resolve. For the time being, do the following to import this python script -\n","Find the file in the drive and download it, then reupload it in the /content folder of the colab file.\n","You will need to do this for every new runtime connection\n","'''\n","from depthwise_conv2d import DepthwiseConvolution2D"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_scaFGj-yqqW","colab_type":"text"},"source":["#LOAD AND PROCESS INPUT"]},{"cell_type":"code","metadata":{"id":"W25qnUPKx1ar","colab_type":"code","colab":{}},"source":["# KEYWORD_FOLDER1= 'Bachao_Data_Old/'\n","# KEYWORD_FOLDER2= 'Bachao_Data_Babble_10dB'\n","# KEYWORD_FOLDER3 = 'Bachao_Data_Natural_10dB'\n","\n","KEYWORD_FOLDER4 = path + 'Help_Data_Old'\n","KEYWORD_FOLDER5 = path + 'Help_Data_10dB'\n","KEYWORD_FOLDER6= path + 'Help_Data_Natural_10dB'\n","\n","\n","# NEGATIVE_FOLDER1 = 'Negative_Data/'\n","# NEGATIVE_FOLDER2 = 'Negative_Data_10dB'\n","# NEGATIVE_FOLDER3 = 'Negative_Data_Natural_10dB'\n","NEGATIVE_FOLDER4 = path + 'Negative_Data/'\n","NEGATIVE_FOLDER5 = path + 'Negative_Data_10dB'\n","NEGATIVE_FOLDER6 = path + 'Negative_Data_Natural_10dB'\n","\n","#OPPPOSITE_KEYWORD_FOLDER = 'Bachao_Data/'\n","KEYWORD_FOLDER_TEST = path + 'Bachao_Data_Test/'\n","NEGATIVE_FOLDER_TEST = path + 'Negative_Data_Test_Old/'\n","#OPPPOSITE_KEYWORD_FOLDER_TEST = 'Bachao_Data_Test/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7OkpCT2yaC4","colab_type":"code","colab":{}},"source":["def count_files(folder, extension):\n","\tcount = 0\n","\tfor file in os.listdir(folder):\n","\t\tif file.endswith(extension):\n","\t\t\tfile_path = os.path.join(folder, file)\n","\t\t\tcount += 1\n","\treturn count\n","\n","def load_data_folder(folder, is_keyword):\n","  num_samples = count_files(folder, '.wav')\n","  data_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","  data_Y = np.zeros((num_samples), dtype=np.float64)\n","\n","  count = 0\n","  for file in os.listdir(folder):\n","    if file.endswith('.wav'):\n","      file_path = os.path.join(folder, file)\n","      y, sr = librosa.load(file_path,sr=None)\n","      mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=128, n_fft=256, n_mfcc=20)\n","      mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n","      mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n","      data_X[count, :, :20] = mfcc.T\n","      data_X[count, :, 20:30] = mfcc_delta.T\n","      data_X[count, :, 30:] = mfcc_double_delta.T\n","      data_Y[count] = int(is_keyword)\n","      count += 1\n","      if count%50==0:\n","        print(count)\n","  return data_X, data_Y\n","\n","def load_data(folders):\n","\tnum_samples = sum([count_files(folder, '.wav') for folder, is_keyword in folders])\n","\tdata_X = np.zeros((num_samples, INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n","\tdata_Y = np.zeros((num_samples), dtype=np.float64)\n","\tcount = 0\n","\tfor folder, is_keyword in folders:\n","\t\tnum_samples_folder = count_files(folder, '.wav')\n","\t\tdata_X[count:count+num_samples_folder, :, :], data_Y[count:count+num_samples_folder] = (\n","\t\t\tload_data_folder(folder, is_keyword))\n","\t\tcount += num_samples_folder\n","\treturn shuffle(data_X, data_Y, random_state=0)\n","\n","def load_train_data():\n","  #folders = [(NEGATIVE_FOLDER_TRAIN_1, False), (NEGATIVE_FOLDER_TRAIN_2, False), (NEGATIVE_FOLDER_TRAIN_3, False)]\n","  folders = [(KEYWORD_FOLDER4, True), (NEGATIVE_FOLDER4, False)]\n","  #folders = [(KEYWORD_FOLDER1, True), (KEYWORD_FOLDER2, True), (KEYWORD_FOLDER3, True), (KEYWORD_FOLDER4, True), (KEYWORD_FOLDER5, True), (KEYWORD_FOLDER6, True), (KEYWORD_FOLDER_TEST, True), (NEGATIVE_FOLDER1, False), (NEGATIVE_FOLDER2, False), (NEGATIVE_FOLDER3, False), (NEGATIVE_FOLDER4, False), (NEGATIVE_FOLDER5, False), (NEGATIVE_FOLDER6, False), (NEGATIVE_FOLDER_TEST, False)]\n","  return load_data(folders)\n","\n","def load_test_data():\n","  #folders = [(NEGATIVE_FOLDER_TEST, True)]\n","  folders = [(KEYWORD_FOLDER_TEST, True), (NEGATIVE_FOLDER_TEST, False)] \n","  return load_data(folders)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVW_Qvwew9ZE","colab_type":"code","colab":{}},"source":["activ_dir = 'white_noise'\n","fs, x = read(path + 'white_noise.wav')\n","file_size = x.shape[0]\n","segment_time = 3.0\n","segment_samples = int(segment_time * fs)\n","no_of_segments = int(file_size/segment_samples)\n","\n","# for i in range(no_of_segments - 1):\n","#   file_name = '{}_{}.wav'.format(activ_dir, i)\n","#   x_temp = x[i*segment_samples:(i+1)*segment_samples]\n","#   write(path + 'white_noice/' + file_name, fs, x_temp)\n","\n","print(fs)\n","print(x.shape)\n","print(file_size)\n","print(segment_samples)\n","print(no_of_segments)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-YgqF6Tyogf","colab_type":"code","colab":{}},"source":["with open(path + 'help_data_total_hari_train_x.pickle', 'rb') as f:\n","  train_X = pickle.load(f)\n","with open(path + 'help_data_total_hari_train_y.pickle', 'rb') as f:\n","  train_Y = pickle.load(f)\n","\n","print(\"Train data extracted\")\n","\n","print(train_Y.sum())\n","print(train_Y.shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azdZw-sUzeK_","colab_type":"code","colab":{}},"source":["np.random.seed(0)\n","np.random.shuffle(train_X)\n","np.random.shuffle(train_Y)\n","\n","train_X_shuffle = train_X\n","train_Y_shuffle = train_Y\n","\n","train_X_shuffle = train_X_shuffle[:,:,:,np.newaxis]\n","\n","print(train_X_shuffle.shape)\n","print(train_Y_shuffle.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RzcNElPGzreC","colab_type":"code","colab":{}},"source":["# import sklearn\n","# train_X_cv, test_X_cv, train_Y_cv, test_Y_cv = sklearn.model_selection.train_test_split(train_X_shuffle, train_Y_shuffle, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YR6FuKaDywOW","colab_type":"text"},"source":["#MODEL"]},{"cell_type":"code","metadata":{"id":"e86H5MrHyxfB","colab_type":"code","colab":{}},"source":["def MobileNet(input_shape=(376,40,1), alpha=1, classes=2):\n","    \"\"\"Instantiates the MobileNet.Network has two hyper-parameters\n","        which are the width of network (controlled by alpha)\n","        and input size.\n","        \n","        # Arguments\n","            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","                to use as image input for the model.\n","            input_shape: optional shape tuple, only to be specified\n","                if `include_top` is False (otherwise the input shape\n","                has to be `(224, 224, 3)` (with `channels_last` data format)\n","                or `(3, 224, 244)` (with `channels_first` data format).\n","                It should have exactly 3 inputs channels,\n","                and width and height should be no smaller than 96.\n","                E.g. `(200, 200, 3)` would be one valid value.\n","            alpha: optional parameter of the network to change the \n","                width of model.\n","            shallow: optional parameter for making network smaller.\n","            classes: optional number of classes to classify images\n","                into.\n","        # Returns\n","            A Keras model instance.\n","        \"\"\"\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = Convolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(img_input)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = DepthwiseConvolution2D(int(512 * alpha), (3, 3), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","    x = Convolution2D(int(512 * alpha), (1, 1), strides=(1, 1), padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('elu')(x)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    out = Dense(classes, activation='softmax')(x)\n","\n","    model = Model(img_input, out, name='mobilenet')\n","\n","    return model\n","\n","def CRNN1(X_shape = (376,40,1), nb_classes = 2):\n","    '''\n","    Model used for evaluation in paper. Inspired by K. Choi model in:\n","    https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/music_tagger_crnn.py\n","    '''\n","\n","    nb_layers = 4  # number of convolutional layers\n","    nb_filters = [256, 512, 512, 512]  # filter sizes\n","    kernel_size = (3, 3)  # convolution kernel size\n","    activation = 'elu'  # activation function to use after each layer\n","    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2),\n","                 (4, 2)]  # size of pooling area\n","\n","    # shape of input data (frequency, time, channels)\n","    input_shape = (X_shape[0], X_shape[1], X_shape[2])\n","    frequency_axis = 1\n","    time_axis = 2\n","    channel_axis = 3\n","\n","    # Create sequential model and normalize along frequency axis\n","    model = Sequential()\n","    #model.add(BatchNormalization(axis=frequency_axis, input_shape=input_shape))\n","\n","    # First convolution layer specifies shape\n","    model.add(Convolution2D(nb_filters[0], kernel_size=kernel_size, padding='same',\n","                     data_format=\"channels_last\",\n","                     input_shape=input_shape))\n","    model.add(Activation(activation))\n","    model.add(BatchNormalization(axis=channel_axis))\n","    model.add(MaxPooling2D(pool_size=pool_size[0], strides=pool_size[0]))\n","    model.add(Dropout(0.1))\n","\n","    # Add more convolutional layers\n","    for layer in range(nb_layers - 1):\n","        # Convolutional layer\n","        model.add(Convolution2D(nb_filters[layer + 1], kernel_size=kernel_size,\n","                         padding='same'))\n","        model.add(Activation(activation))\n","        model.add(BatchNormalization(\n","            axis=channel_axis))  # Improves overfitting/underfitting\n","        model.add(MaxPooling2D(pool_size=pool_size[layer + 1],\n","                               strides=pool_size[layer + 1]))  # Max pooling\n","        model.add(Dropout(0.1))\n","\n","        # Reshaping input for recurrent layer\n","    # (frequency, time, channels) --> (time, frequency, channel)\n","    model.add(Permute((time_axis, frequency_axis, channel_axis)))\n","    resize_shape = model.output_shape[2] * model.output_shape[3]\n","    model.add(Reshape((model.output_shape[1], resize_shape)))\n","\n","    # recurrent layer\n","    model.add(Bidirectional(GRU(256, return_sequences=True)))\n","    model.add(Bidirectional(GRU(256, return_sequences=False)))\n","    model.add(Dropout(0.3))\n","\n","    # Output layer\n","    model.add(Dense(nb_classes))\n","    model.add(Activation(\"softmax\"))\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLJ1gjbdtFFT","colab_type":"code","colab":{}},"source":["model = CRNN1()\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK2hgu3fENgP","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","model.compile(optimizer = Adam(learning_rate = 0.001),loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics = ['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7JMmm63g3NW","colab_type":"code","colab":{}},"source":["model.fit(x=train_X_shuffle,y=train_Y_shuffle,batch_size=64,epochs=10,validation_split=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1QHCEsGhhfG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}